{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2579cf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_lib.py\n",
    "from pyspark.sql import functions as F, Window\n",
    "from langchain_core.tools import tool\n",
    "from typing import List\n",
    "# feature_agent.py\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b0e352",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def generate_base_aggregations(\n",
    "        agg_func: str, \n",
    "        cols_to_agg: List[str]=None, \n",
    "        group_by_cols: List[str]=None,\n",
    "        round_dec_points: int = 2,\n",
    "    ) -> str:\n",
    "    \"\"\"\n",
    "    Generate pyspark code for based aggregations on a dataframe using df.transform() construct.\n",
    "    Args:\n",
    "        agg_func (str): Aggregation function to apply (e.g., \"sum\", \"avg\").\n",
    "        cols_to_agg (List[str]): List of columns to aggregate.\n",
    "        group_by_cols (List[str]): List of columns to group by.\n",
    "        round_dec_points (int): Number of decimal points to round the result.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        f'.transform(base_aggregations,'\n",
    "        f'agg_func=\"{agg_func}\", '\n",
    "        f'cols_to_agg={cols_to_agg}, '\n",
    "        f'group_by_cols={group_by_cols})'\n",
    "        f'round_dec_points={round_dec_points})'\n",
    "    )\n",
    "\n",
    "@tool\n",
    "def generate_rolling_window_code(\n",
    "    partition_cols: List[str],\n",
    "    order_col: str,\n",
    "    agg_func: str,\n",
    "    num_cols_to_agg: List[str],\n",
    "    window_size_in_days: List[int],\n",
    "    window_offset: int = 0,\n",
    "    round_dec_points: int = 2\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate PySpark code for rolling window aggregations using df.transform() construct.\n",
    "    Args:\n",
    "        partition_cols (List[str]): List of columns to partition by.\n",
    "        order_col (str): Column to order by within each partition.\n",
    "        agg_func (str): Aggregation function to apply (e.g., \"sum\", \"avg\").\n",
    "        num_cols_to_agg (List[str]): List of numerical columns to apply aggregations on.\n",
    "        window_size_in_days (int): List of window sized (in days) to apply the aggregation (inclusive).\n",
    "        window_offset (int): Lower window row offset (inclusive).\n",
    "        round_dec_points (int): Number of decimal points to round the result.\n",
    "    \n",
    "    \"\"\"\n",
    "    return (\n",
    "        f'.transform(rolling_window_aggregations,'\n",
    "        f'agg_func=\"{agg_func}\",'\n",
    "        f'partition_cols={partition_cols},'\n",
    "        f'order_col=\"{order_col}\",'\n",
    "        f'num_cols_to_agg={num_cols_to_agg},'\n",
    "        f'window_size_in_days={window_size_in_days},'\n",
    "        f'window_offset={window_offset})'\n",
    "        f'round_dec_points={round_dec_points}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd6c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load variables from .env into environment\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the key\n",
    "LLM_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "print(\"Loaded API Key:\", LLM_API_KEY is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cc0826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LLM ---\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    google_api_key=LLM_API_KEY,\n",
    "    temperature=0\n",
    ")\n",
    "# --- Tools ---\n",
    "tools = [generate_base_aggregations, generate_rolling_window_code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6374d4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prompt ---\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "               You are a feature engineering code assistant.\n",
    "               You generate PySpark pipeline code using .transform(function, param-value, ...) constructs\n",
    "                based on the provided data schema and the user feaure requests.\n",
    "               You do not generate any other code.\n",
    "               Return only valid PySpark code snippets that can be directly used to run the pipeline like below:\n",
    "                \n",
    "                df_output = df.transform(\n",
    "                                apply_base_aggregations,\n",
    "                                agg_func='sum',\n",
    "                                cols_to_agg=['sales'],\n",
    "                                group_by_cols=['region'])\n",
    "                                round_dec_points=2\n",
    "                            )\n",
    "                            .transform(\n",
    "                                apply_rolling_window,\n",
    "                                agg_func='sum',\n",
    "                                partition_cols=['region'],\n",
    "                                order_col='date',\n",
    "                                num_cols_to_agg=['sales'],\n",
    "                                window_size_in_days=[2, 3],\n",
    "                                window_offset=0,\n",
    "                                round_dec_points=2\n",
    "                        )\n",
    "                Do return the output code as in string format with parameters in new lines as shown above in the example.\n",
    "                Do not return any other text, comments, or explanations.   \n",
    "     \"\"\"),\n",
    "    (\"human\", \"Schem:\\n {schema}\\n\\n Feature request:\\n {feature_request}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcf73b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Agent + Executor ---\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(\n",
    "                    agent=agent, \n",
    "                    tools=tools, \n",
    "                    verbose=True, \n",
    "                    return_intermediate_steps=True, \n",
    "                    handle_parsing_errors=True,\n",
    "                    max_iterations=3,\n",
    "                    max_execution_time=60,\n",
    "                    early_stopping_method=\"generate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4fb527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Example Run ---\n",
    "schema = \"\"\"\n",
    "root\n",
    "    |-- cutomer_id: string (nullable = true)\n",
    "    |-- edi_business_date: date (nullable = true)\n",
    "    |-- event_cnt: double (nullable = true)\n",
    "    |-- event_type_login_cnt: double (nullable = true)\n",
    "    |-- event_type_payment_cnt: double (nullable = true)\n",
    "\"\"\"\n",
    "\n",
    "feature_request = \"\"\"\n",
    "Create below features for given data:\n",
    "1. Average event count per customer.\n",
    "2. Rolling 7-day and 3-day sum, average and count of event_type_login_cnt and event_type_payment_cnt per customer.\n",
    "3. Total event counts per customer daily, across different event  types.\n",
    "\"\"\"\n",
    "\n",
    "result = agent_executor.invoke({\n",
    "    \"schema\": schema,\n",
    "    \"feature_request\": feature_request\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46cc833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final assembled pipeline code\n",
    "pipeline_code = \"\".join(result[\"output\"])\n",
    "print(\"\\nGenerated PySpark Pipeline:\\n\")\n",
    "print(pipeline_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8c571c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c007c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
